{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI-Identifiability Regularization Experiments\n",
    "\n",
    "This notebook runs all regularization experiments for testing identifiability of MI criteria.\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Upload your code files\n",
    "3. Run baseline and regularization experiments\n",
    "4. Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enable GPU in Colab\n",
    "\n",
    "**IMPORTANT: Before running any code, enable GPU:**\n",
    "\n",
    "1. Click **Runtime** in the top menu\n",
    "2. Select **Change runtime type**\n",
    "3. Under **Hardware accelerator**, select **T4 GPU** (or any available GPU)\n",
    "4. Click **Save**\n",
    "\n",
    "Then run the cells below to verify GPU access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU is available!\")\n",
    "    print(f\"  GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    DEVICE = 'cuda:0'\n",
    "else:\n",
    "    print(\"✗ No GPU available. Please enable GPU in Runtime > Change runtime type\")\n",
    "    print(\"  Falling back to CPU (will be slower)\")\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install tqdm matplotlib numpy scipy pandas torch networkx torchvision seaborn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Mount Google Drive (optional - for saving results)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"Not running in Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Your Code Files\n",
    "\n",
    "You have two options:\n",
    "\n",
    "**Option A: Upload files directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"Please upload the following files:\")\n",
    "    print(\"- main.py\")\n",
    "    print(\"- analyze_regularization.py\")\n",
    "    print(\"- setup.py\")\n",
    "    print(\"- The entire 'mi_identifiability' folder (zipped)\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # If mi_identifiability is uploaded as a zip, extract it\n",
    "    import zipfile\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            print(f\"Extracted {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Clone from GitHub (if your code is in a repo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify if cloning from GitHub\n",
    "# !git clone https://github.com/YOUR_USERNAME/MI-identifiability.git\n",
    "# %cd MI-identifiability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that required files exist\n",
    "import os\n",
    "\n",
    "required_files = ['main.py', 'analyze_regularization.py']\n",
    "required_dirs = ['mi_identifiability']\n",
    "\n",
    "print(\"Checking for required files...\")\n",
    "for f in required_files:\n",
    "    if os.path.exists(f):\n",
    "        print(f\"✓ {f} found\")\n",
    "    else:\n",
    "        print(f\"✗ {f} NOT FOUND\")\n",
    "\n",
    "for d in required_dirs:\n",
    "    if os.path.isdir(d):\n",
    "        print(f\"✓ {d}/ directory found\")\n",
    "    else:\n",
    "        print(f\"✗ {d}/ directory NOT FOUND\")\n",
    "\n",
    "# List all files in current directory\n",
    "print(\"\\nCurrent directory contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline (no regularization)\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 100 --size 3 --depth 2 \\\n",
    "    --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run L1 Regularization Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularization experiments\n",
    "l1_lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "\n",
    "for lambda_val in l1_lambdas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running L1 experiment with lambda={lambda_val}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    !python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "        --target-logic-gates XOR \\\n",
    "        --n-experiments 100 --size 3 --depth 2 \\\n",
    "        --l1-lambda {lambda_val} \\\n",
    "        --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run L2 Regularization Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization experiments\n",
    "l2_lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "for lambda_val in l2_lambdas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running L2 experiment with lambda={lambda_val}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    !python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "        --target-logic-gates XOR \\\n",
    "        --n-experiments 100 --size 3 --depth 2 \\\n",
    "        --l2-lambda {lambda_val} \\\n",
    "        --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Dropout Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout experiments\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running Dropout experiment with rate={rate}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    !python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "        --target-logic-gates XOR \\\n",
    "        --n-experiments 100 --size 3 --depth 2 \\\n",
    "        --dropout-rate {rate} \\\n",
    "        --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis on all results\n",
    "!python analyze_regularization.py logs --output-dir analysis_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary\n",
    "with open('analysis_output/analysis_summary.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical test results\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nL1 Statistical Tests:\")\n",
    "if os.path.exists('analysis_output/l1_statistical_tests.csv'):\n",
    "    df_l1 = pd.read_csv('analysis_output/l1_statistical_tests.csv')\n",
    "    display(df_l1)\n",
    "\n",
    "print(\"\\nL2 Statistical Tests:\")\n",
    "if os.path.exists('analysis_output/l2_statistical_tests.csv'):\n",
    "    df_l2 = pd.read_csv('analysis_output/l2_statistical_tests.csv')\n",
    "    display(df_l2)\n",
    "\n",
    "print(\"\\nDropout Statistical Tests:\")\n",
    "if os.path.exists('analysis_output/dropout_statistical_tests.csv'):\n",
    "    df_dropout = pd.read_csv('analysis_output/dropout_statistical_tests.csv')\n",
    "    display(df_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "plot_files = glob.glob('analysis_output/*.png')\n",
    "for plot_file in sorted(plot_files):\n",
    "    print(f\"\\n{plot_file}:\")\n",
    "    display(Image(filename=plot_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Create a zip file of all results\n",
    "    !zip -r results.zip logs analysis_output\n",
    "    \n",
    "    # Download\n",
    "    from google.colab import files\n",
    "    files.download('results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Copy results to Google Drive\n",
    "    !cp -r logs /content/drive/MyDrive/MI_identifiability_logs\n",
    "    !cp -r analysis_output /content/drive/MyDrive/MI_identifiability_analysis\n",
    "    print(\"Results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Run Smaller Test First\n",
    "\n",
    "If you want to test with fewer experiments first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with just 10 experiments\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 10 --size 3 --depth 2 \\\n",
    "    --device {DEVICE}\n",
    "\n",
    "# Test with one L1 value\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 10 --size 3 --depth 2 \\\n",
    "    --l1-lambda 0.001 \\\n",
    "    --device {DEVICE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
