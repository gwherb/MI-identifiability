{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI-Identifiability Regularization Experiments\n",
    "\n",
    "This notebook runs all regularization experiments for testing identifiability of MI criteria.\n",
    "\n",
    "## ðŸ”’ AUTO-SAVE PROTECTION\n",
    "**NEW: Results automatically save to Google Drive after each experiment!**\n",
    "- Never lose your results from runtime disconnections\n",
    "- Each session creates a timestamped folder\n",
    "- Results saved incrementally as experiments complete\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Mount Google Drive (for auto-save)\n",
    "3. Upload your code files\n",
    "4. Run baseline and regularization experiments\n",
    "5. Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enable GPU in Colab\n",
    "\n",
    "**IMPORTANT: Before running any code, enable GPU:**\n",
    "\n",
    "1. Click **Runtime** in the top menu\n",
    "2. Select **Change runtime type**\n",
    "3. Under **Hardware accelerator**, select **T4 GPU** (or any available GPU)\n",
    "4. Click **Save**\n",
    "\n",
    "Then run the cells below to verify GPU access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU is available!\")\n",
    "    print(f\"  GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    DEVICE = 'cuda:0'\n",
    "else:\n",
    "    print(\"âœ— No GPU available. Please enable GPU in Runtime > Change runtime type\")\n",
    "    print(\"  Falling back to CPU (will be slower)\")\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install tqdm matplotlib numpy scipy pandas torch networkx torchvision seaborn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Colab and setup auto-save to Drive\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Mount Google Drive for automatic saving\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Create timestamped folder for this session\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    DRIVE_SAVE_DIR = f'/content/drive/MyDrive/MI_Experiments_{timestamp}'\n",
    "    os.makedirs(DRIVE_SAVE_DIR, exist_ok=True)\n",
    "    os.makedirs(f'{DRIVE_SAVE_DIR}/logs', exist_ok=True)\n",
    "    os.makedirs(f'{DRIVE_SAVE_DIR}/analysis', exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ“ AUTO-SAVE ENABLED!\")\n",
    "    print(f\"Results will be saved to: {DRIVE_SAVE_DIR}\")\n",
    "    print(f\"This protects you from losing results if runtime disconnects!\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "else:\n",
    "    print(\"Not running in Colab\")\n",
    "    DRIVE_SAVE_DIR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to save results immediately after each experiment\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def save_latest_results_to_drive():\n",
    "    \"\"\"Save the latest experiment results to Google Drive immediately.\"\"\"\n",
    "    if not IN_COLAB or DRIVE_SAVE_DIR is None:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Find all run directories\n",
    "        run_dirs = glob.glob('/content/logs/run_*')\n",
    "        if not run_dirs:\n",
    "            print(\"âš  No results to save yet\")\n",
    "            return\n",
    "        \n",
    "        # Copy entire logs directory\n",
    "        print(f\"\\nðŸ’¾ Saving results to Google Drive...\")\n",
    "        \n",
    "        # Remove old backup and create fresh copy\n",
    "        drive_logs = f'{DRIVE_SAVE_DIR}/logs'\n",
    "        if os.path.exists(drive_logs):\n",
    "            shutil.rmtree(drive_logs)\n",
    "        shutil.copytree('/content/logs', drive_logs)\n",
    "        \n",
    "        print(f\"âœ“ Saved {len(run_dirs)} experiment runs to Drive\")\n",
    "        print(f\"  Location: {drive_logs}\")\n",
    "        \n",
    "        # Also save a progress log\n",
    "        with open(f'{DRIVE_SAVE_DIR}/progress.txt', 'a') as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Saved {len(run_dirs)} runs\\n\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš  Error saving to Drive: {e}\")\n",
    "        print(\"  Your results are still in /content/logs\")\n",
    "        return False\n",
    "\n",
    "print(\"âœ“ Auto-save helper function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Your Code Files\n",
    "\n",
    "You have two options:\n",
    "\n",
    "**Option A: Upload files directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"Please upload the following files:\")\n",
    "    print(\"- main.py\")\n",
    "    print(\"- analyze_regularization.py\")\n",
    "    print(\"- setup.py\")\n",
    "    print(\"- The entire 'mi_identifiability' folder (zipped)\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # If mi_identifiability is uploaded as a zip, extract it\n",
    "    import zipfile\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            print(f\"Extracted {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Clone from GitHub (if your code is in a repo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify if cloning from GitHub\n",
    "# !git clone https://github.com/YOUR_USERNAME/MI-identifiability.git\n",
    "# %cd MI-identifiability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that required files exist\n",
    "import os\n",
    "\n",
    "required_files = ['main.py', 'analyze_regularization.py']\n",
    "required_dirs = ['mi_identifiability']\n",
    "\n",
    "print(\"Checking for required files...\")\n",
    "for f in required_files:\n",
    "    if os.path.exists(f):\n",
    "        print(f\"âœ“ {f} found\")\n",
    "    else:\n",
    "        print(f\"âœ— {f} NOT FOUND\")\n",
    "\n",
    "for d in required_dirs:\n",
    "    if os.path.isdir(d):\n",
    "        print(f\"âœ“ {d}/ directory found\")\n",
    "    else:\n",
    "        print(f\"âœ— {d}/ directory NOT FOUND\")\n",
    "\n",
    "# List all files in current directory\n",
    "print(\"\\nCurrent directory contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Baseline Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Quick Test (1 experiment)\n",
    "\n",
    "First, let's run just 1 experiment to verify everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with just 1 experiment to verify setup\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 1 --size 3 --depth 2 \\\n",
    "    --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Full Baseline (100 experiments)\n",
    "\n",
    "If the test above worked, run the full baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline (no regularization)\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 100 --size 3 --depth 2 \\\n",
    "    --device {DEVICE}\n",
    "\n",
    "# Automatically save results to Drive\n",
    "save_latest_results_to_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Check Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if results were saved\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"Checking for saved results...\\n\")\n",
    "\n",
    "# Find all run directories\n",
    "run_dirs = glob.glob('/content/logs/run_*')\n",
    "print(f\"Found {len(run_dirs)} run directories:\")\n",
    "for d in sorted(run_dirs):\n",
    "    print(f\"  {d}\")\n",
    "\n",
    "if run_dirs:\n",
    "    latest_run = sorted(run_dirs)[-1]\n",
    "    print(f\"\\nLatest run: {latest_run}\")\n",
    "    \n",
    "    # Check what files exist\n",
    "    print(f\"\\nFiles in latest run:\")\n",
    "    !ls -lh {latest_run}\n",
    "    \n",
    "    # Try to read the results\n",
    "    import pandas as pd\n",
    "    \n",
    "    df_out_path = f\"{latest_run}/df_out.csv\"\n",
    "    if os.path.exists(df_out_path):\n",
    "        df = pd.read_csv(df_out_path)\n",
    "        print(f\"\\nâœ“ Results file found with {len(df)} rows\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(\"\\nâš  WARNING: Results file is empty!\")\n",
    "            print(\"This means no experiments converged successfully.\")\n",
    "            print(\"\\nPossible reasons:\")\n",
    "            print(\"1. Model isn't converging (loss/accuracy not meeting thresholds)\")\n",
    "            print(\"2. Training is failing silently\")\n",
    "            print(\"3. GPU issues\")\n",
    "            \n",
    "            # Check the log file\n",
    "            log_path = f\"{latest_run}/output.log\"\n",
    "            if os.path.exists(log_path):\n",
    "                print(\"\\nChecking log file for 'No convergence' messages...\")\n",
    "                !grep -c \"No convergence\" {log_path} || echo \"No convergence messages found\"\n",
    "                print(\"\\nLast 20 lines of log:\")\n",
    "                !tail -20 {log_path}\n",
    "    else:\n",
    "        print(f\"\\nâœ— No df_out.csv found\")\n",
    "        \n",
    "        # Check for data_tmp.csv\n",
    "        tmp_path = f\"{latest_run}/data_tmp.csv\"\n",
    "        if os.path.exists(tmp_path):\n",
    "            df_tmp = pd.read_csv(tmp_path)\n",
    "            print(f\"\\nâœ“ Temporary data file found with {len(df_tmp)} rows\")\n",
    "        else:\n",
    "            print(\"\\nâœ— No temporary data file found either\")\n",
    "else:\n",
    "    print(\"\\nâœ— No run directories found at all!\")\n",
    "    print(\"The experiments may have failed to start.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run L1 Regularization Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularization experiments\n",
    "l1_lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "\n",
    "for lambda_val in l1_lambdas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running L1 experiment with lambda={lambda_val}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    !python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "        --target-logic-gates XOR \\\n",
    "        --n-experiments 100 --size 3 --depth 2 \\\n",
    "        --l1-lambda {lambda_val} \\\n",
    "        --device {DEVICE}\n",
    "    \n",
    "    # Save after each lambda value completes\n",
    "    print(f\"\\nCompleted L1 lambda={lambda_val}\")\n",
    "    save_latest_results_to_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run L2 Regularization Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization experiments\n",
    "l2_lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "for lambda_val in l2_lambdas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running L2 experiment with lambda={lambda_val}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    !python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "        --target-logic-gates XOR \\\n",
    "        --n-experiments 100 --size 3 --depth 2 \\\n",
    "        --l2-lambda {lambda_val} \\\n",
    "        --device {DEVICE}\n",
    "    \n",
    "    # Save after each lambda value completes\n",
    "    print(f\"\\nCompleted L2 lambda={lambda_val}\")\n",
    "    save_latest_results_to_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Dropout Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout experiments\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running Dropout experiment with rate={rate}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    !python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "        --target-logic-gates XOR \\\n",
    "        --n-experiments 100 --size 3 --depth 2 \\\n",
    "        --dropout-rate {rate} \\\n",
    "        --device {DEVICE}\n",
    "    \n",
    "    # Save after each dropout rate completes\n",
    "    print(f\"\\nCompleted Dropout rate={rate}\")\n",
    "    save_latest_results_to_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis on all results\n",
    "!python analyze_regularization.py logs --output-dir analysis_output\n",
    "\n",
    "# Save analysis results to Drive\n",
    "if IN_COLAB and DRIVE_SAVE_DIR:\n",
    "    import shutil\n",
    "    if os.path.exists('analysis_output'):\n",
    "        drive_analysis = f'{DRIVE_SAVE_DIR}/analysis'\n",
    "        if os.path.exists(drive_analysis):\n",
    "            shutil.rmtree(drive_analysis)\n",
    "        shutil.copytree('analysis_output', drive_analysis)\n",
    "        print(f\"\\nâœ“ Analysis saved to: {drive_analysis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary\n",
    "with open('analysis_output/analysis_summary.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical test results\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nL1 Statistical Tests:\")\n",
    "if os.path.exists('analysis_output/l1_statistical_tests.csv'):\n",
    "    df_l1 = pd.read_csv('analysis_output/l1_statistical_tests.csv')\n",
    "    display(df_l1)\n",
    "\n",
    "print(\"\\nL2 Statistical Tests:\")\n",
    "if os.path.exists('analysis_output/l2_statistical_tests.csv'):\n",
    "    df_l2 = pd.read_csv('analysis_output/l2_statistical_tests.csv')\n",
    "    display(df_l2)\n",
    "\n",
    "print(\"\\nDropout Statistical Tests:\")\n",
    "if os.path.exists('analysis_output/dropout_statistical_tests.csv'):\n",
    "    df_dropout = pd.read_csv('analysis_output/dropout_statistical_tests.csv')\n",
    "    display(df_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "plot_files = glob.glob('analysis_output/*.png')\n",
    "for plot_file in sorted(plot_files):\n",
    "    print(f\"\\n{plot_file}:\")\n",
    "    display(Image(filename=plot_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Create a zip file of all results\n",
    "    !zip -r results.zip logs analysis_output\n",
    "    \n",
    "    # Download\n",
    "    from google.colab import files\n",
    "    files.download('results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Results Already Saved!\n",
    "\n",
    "âœ“ Your results are being automatically saved to Google Drive after each experiment!\n",
    "\n",
    "Location: Check `MI_Experiments_[TIMESTAMP]` folder in your Drive\n",
    "\n",
    "The folder contains:\n",
    "- `logs/` - All experiment results\n",
    "- `analysis/` - Analysis outputs\n",
    "- `progress.txt` - Log of what's been saved\n",
    "\n",
    "You can also manually verify or copy additional files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB and DRIVE_SAVE_DIR:\n",
    "    print(f\"Your results are saved at: {DRIVE_SAVE_DIR}\")\n",
    "    print(f\"\\nFolder contents:\")\n",
    "    !ls -lh {DRIVE_SAVE_DIR}\n",
    "    print(f\"\\nNumber of experiment runs saved:\")\n",
    "    !ls -d {DRIVE_SAVE_DIR}/logs/run_* 2>/dev/null | wc -l\n",
    "    \n",
    "    # Show progress log\n",
    "    progress_file = f\"{DRIVE_SAVE_DIR}/progress.txt\"\n",
    "    if os.path.exists(progress_file):\n",
    "        print(f\"\\nSave history:\")\n",
    "        with open(progress_file, 'r') as f:\n",
    "            print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Run Smaller Test First\n",
    "\n",
    "If you want to test with fewer experiments first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with just 10 experiments\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 10 --size 3 --depth 2 \\\n",
    "    --device {DEVICE}\n",
    "\n",
    "# Test with one L1 value\n",
    "!python main.py --verbose --val-frequency 1 --noise-std 0.0 \\\n",
    "    --target-logic-gates XOR \\\n",
    "    --n-experiments 10 --size 3 --depth 2 \\\n",
    "    --l1-lambda 0.001 \\\n",
    "    --device {DEVICE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
